{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Augmentation",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzqfAYVQ9VT2",
        "colab_type": "text"
      },
      "source": [
        "## Imports & Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LytJiIm7W5xU",
        "colab_type": "code",
        "outputId": "463191b8-6a72-49d5-cfe9-c0d0a21f9759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "pip install elasticdeform"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting elasticdeform\n",
            "  Downloading https://files.pythonhosted.org/packages/41/67/931371b1434b919537c43867ef45dae8af985a7331ae5b6d0e47bddfc875/elasticdeform-0.4.6.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from elasticdeform) (1.18.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from elasticdeform) (1.4.1)\n",
            "Building wheels for collected packages: elasticdeform\n",
            "  Building wheel for elasticdeform (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elasticdeform: filename=elasticdeform-0.4.6-cp36-cp36m-linux_x86_64.whl size=70442 sha256=8dd40aae66c71a03ae8fc3fbd2dd25545f036aa54ee256e8c326d82a3c805e6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/3a/94/a1d69f8b9da44826a171395e67f9f7a117f89af18f206481dd\n",
            "Successfully built elasticdeform\n",
            "Installing collected packages: elasticdeform\n",
            "Successfully installed elasticdeform-0.4.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yALhkP4y9HdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image, ImageSequence\n",
        "import elasticdeform\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXaQYrfr8xVp",
        "colab_type": "text"
      },
      "source": [
        "## Data Augmentation\n",
        "\n",
        "The following folders are required for each dataset:\n",
        "\n",
        "- For the ISBI segmentation challenge dataset: `segmentation_challenge_data`\n",
        "- For the DIC-HeLa dataset: `cell_tracking_challenge_data/DIC-C2DH-HeLa_train` and `cell_tracking_challenge_data/DIC-C2DH-HeLa_test`\n",
        "- For the PhC-U373 dataset: `cell_tracking_challenge_data/PhC-C2DH-U373_train` and `cell_tracking_challenge_data/PhC-C2DH-U373_test`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfYn552J9m32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makedir(path: str):\n",
        "    \"\"\"\n",
        "    Creates a directory with the specified path if it does not exist yet.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    path: str\n",
        "        the file path of the directory that should be created\n",
        "    \"\"\"\n",
        "    current_directory = os.getcwd()\n",
        "    final_directory = os.path.join(current_directory, rf'{path}')\n",
        "    if not os.path.exists(final_directory):\n",
        "        os.makedirs(final_directory)\n",
        "\n",
        "\n",
        "def make_data_dirs(path: str, factor: int) -> Tuple[str, str, str, str]:\n",
        "    \"\"\"\n",
        "    Creates the directories for the training and test datasets.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    path: str\n",
        "        the file path to the directory in which the new directories should be created\n",
        "    factor: int\n",
        "        the factor with which the size of the dataset is increased\n",
        "    \"\"\"\n",
        "    train_output_path = f'{path}/augmented/train_{factor}x'\n",
        "    train_label_output_path = f'{path}/augmented/train_labels_{factor}x'\n",
        "    test_output_path = f'{path}/augmented/test_{factor}x'\n",
        "    test_label_output_path = f'{path}/augmented/test_labels_{factor}x'\n",
        "    makedir(train_output_path)\n",
        "    makedir(train_label_output_path)\n",
        "    makedir(test_output_path)\n",
        "    makedir(test_label_output_path)\n",
        "\n",
        "    return train_output_path, train_label_output_path, test_output_path, test_label_output_path\n",
        "\n",
        "\n",
        "def crop_center(image: Image, width: int, height: int) -> Image:\n",
        "    \"\"\"\n",
        "    Crops an image from the center to have the specified width and height.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    image: Image\n",
        "        a PIL.Image that represents the image to be cropped\n",
        "    width: int\n",
        "        the width the image should be cropped to\n",
        "    height: int\n",
        "        the height the image should be cropped to\n",
        "    Returns\n",
        "    ------\n",
        "    Image\n",
        "        the cropped image\n",
        "    \"\"\"\n",
        "    y, x = image.shape\n",
        "    start_x = x // 2 - (width // 2)\n",
        "    start_y = y // 2 - (height // 2)\n",
        "    return image[start_y:start_y + height, start_x:start_x + width]\n",
        "\n",
        "\n",
        "def augment_image(image: Image, label: Image, output_size: Tuple[int, int] = (700, 700), rotation: bool = False, angle:int = 45) -> Tuple[np.array, np.array]:\n",
        "    \"\"\" Augments an image and its label using the same transformations. First the images are padded by mirroring the\n",
        "    image along the borders. This is to ensure that the pixels in the border region of the image will have enough\n",
        "    context during convolution.\n",
        "\n",
        "    If rotation=True, the images will be rotated with the specified angle.\n",
        "\n",
        "    Elastic deformations are performed over a 3x3 grid. The displacements are sampled from a Gaussian distribution with\n",
        "    a standard deviation of 10 pixels.\n",
        "\n",
        "    Finally, the images are cropped to the output size to remove any artifacts on the image borders caused by the\n",
        "    elastic deformation.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    image: Image\n",
        "        a PIL.Image that represents the image to be augmented\n",
        "    label: Image\n",
        "        a PIL.Image that represents the label of the image to be augmented\n",
        "    output_size: (int, int)\n",
        "        represents the size the augmented images should be when they are returned\n",
        "    rotation: bool\n",
        "        whether to apply rotations on the image and label\n",
        "    angle: int\n",
        "        the angle the images should be rotated\n",
        "    Returns\n",
        "    ------\n",
        "    image_array, label_array: Tuple[np.array, np.array]\n",
        "        the augmented image and label\n",
        "    \"\"\"\n",
        "    image_array = np.array(image)\n",
        "    label_array = np.array(label)\n",
        "\n",
        "    # Ensure there is enough padding in case output size = image size\n",
        "    pad_width = output_size[0] - image_array.shape[0] + 200\n",
        "    pad_height = output_size[1] - image_array.shape[1] + 200\n",
        "\n",
        "    image_array = np.pad(image_array, pad_width=[(pad_width, pad_width), (pad_height, pad_height)], mode='symmetric')\n",
        "    label_array = np.pad(label_array, pad_width=[(pad_width, pad_width), (pad_height, pad_height)], mode='symmetric')\n",
        "\n",
        "    if rotation:\n",
        "        image_array = rotate(image_array, angle=angle)\n",
        "        label_array = rotate(label_array, angle=angle)\n",
        "\n",
        "    image_array, label_array = elasticdeform.deform_random_grid([image_array, label_array], sigma=10, points=3,\n",
        "                                                                order=[3, 0])\n",
        "\n",
        "    image_array = crop_center(image_array, output_size[0], output_size[1])\n",
        "    label_array = crop_center(label_array, output_size[0], output_size[1])\n",
        "\n",
        "    return image_array, label_array\n",
        "\n",
        "\n",
        "def augment_segmentation_dataset(factor: int, rotation: bool = False):\n",
        "    \"\"\" Augments the ISBI Challenge Segmentation dataset.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    factor: int\n",
        "        the factor with which the size of the dataset should increase\n",
        "    rotation: bool\n",
        "        whether to apply rotations on the images\n",
        "    \"\"\"\n",
        "    train, train_label, test, test_label = make_data_dirs(\"segmentation_challenge_data\", factor)\n",
        "\n",
        "    training_image_volume = Image.open(\"segmentation_challenge_data/train-volume.tif\")\n",
        "    training_label_volume = Image.open(\"segmentation_challenge_data/train-labels.tif\")\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    for image in ImageSequence.Iterator(training_image_volume):\n",
        "        images.append(image.copy())\n",
        "\n",
        "    for label in ImageSequence.Iterator(training_label_volume):\n",
        "        labels.append(label.copy())\n",
        "\n",
        "    augment_dataset(factor, images, labels, train, train_label, test, test_label, rotation)\n",
        "\n",
        "\n",
        "def augment_phc_dataset(factor: int, rotation: bool = False):\n",
        "    \"\"\" Augments the PhC-U373 dataset.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    factor: int\n",
        "        the factor with which the size of the dataset should increase\n",
        "    rotation: bool\n",
        "        whether to apply rotations on the images\n",
        "    \"\"\"\n",
        "    train, train_label, test, test_label = make_data_dirs(\"cell_tracking_challenge_data/PhC-C2DH-U373_train\", factor)\n",
        "\n",
        "    images = list(map(Image.open, glob.glob('cell_tracking_challenge_data/PhC-C2DH-U373_train/01/*.tif')))\n",
        "    images.extend(list(map(Image.open, glob.glob('cell_tracking_challenge_data/PhC-C2DH-U373_train/02/*.tif'))))\n",
        "    labels = list(map(Image.open, glob.glob('cell_tracking_challenge_data/PhC-C2DH-U373_train/01_GT/*.tif')))\n",
        "    labels.extend(list(map(Image.open, glob.glob('cell_tracking_challenge_data/PhC-C2DH-U373_train/02_GT/*.tif'))))\n",
        "\n",
        "    augment_dataset(factor, images, labels, train, train_label, test, test_label, rotation)\n",
        "\n",
        "\n",
        "def augment_dic_dataset(factor: int, rotation: bool = False):\n",
        "    \"\"\" Augments the DIC-HeLa dataset.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    factor: int\n",
        "        the factor with which the size of the dataset should increase\n",
        "    rotation: bool\n",
        "        whether to apply rotations on the images\n",
        "    \"\"\"\n",
        "    train, train_label, test, test_label = make_data_dirs(\"cell_tracking_challenge_data/DIC-C2DH-HeLa_train\", factor)\n",
        "\n",
        "    images = list(map(Image.open, glob.glob('cell_tracking_challenge_data/DIC-C2DH-HeLa_train/01/*.tif')))\n",
        "    images.extend(list(map(Image.open, glob.glob('cell_tracking_challenge_data/DIC-C2DH-HeLa_train/02/*.tif'))))\n",
        "    labels = list(map(Image.open, glob.glob('cell_tracking_challenge_data/DIC-C2DH-HeLa_train/01_GT/*.tif')))\n",
        "    labels.extend(list(map(Image.open, glob.glob('cell_tracking_challenge_data/DIC-C2DH-HeLa_train/02_GT/*.tif'))))\n",
        "\n",
        "    augment_dataset(factor, images, labels, train, train_label, test, test_label, rotation)\n",
        "\n",
        "\n",
        "def augment_dataset(factor: int, images: [Image], labels: [Image], train_path: str, train_label_path: str,\n",
        "                    test_path: str, test_label_path: str, rotation: bool = False):\n",
        "    \"\"\" Augments a dataset by augmenting each image in the dataset a `factor` number of times. The dataset is split in\n",
        "    a train and test set and all augmented images are saved in their respective folders.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    factor: int\n",
        "        the factor with which the size of the dataset should increase\n",
        "    images: [Image]\n",
        "        an array of PIL.Image that represents the images to be augmented\n",
        "    labels: [Image]\n",
        "        an array of PIL.Image that represents the labels of the images to be augmented\n",
        "    train_path: str\n",
        "        the path the images from the training set should be saved to\n",
        "    train_label_path: str\n",
        "        the path the labels from the training set should be saved to\n",
        "    test_path: str\n",
        "        the path the images from the test set should be saved to\n",
        "    test_label_path: str\n",
        "        the path the labels from the test set should be saved to\n",
        "    rotation: bool\n",
        "        whether to apply rotations on the images\n",
        "    \"\"\"\n",
        "    test_cut = math.floor(len(images) * 0.1)\n",
        "\n",
        "    for i, (image, label) in enumerate(zip(images, labels)):\n",
        "        if i < test_cut:\n",
        "            for j in range(factor):\n",
        "                augmented_image, augmented_label = augment_image(image, label, rotation=rotation)\n",
        "                Image.fromarray(augmented_image).save(f\"{test_path}/test_{j}_{i}.tif\", \"tiff\")\n",
        "                Image.fromarray(augmented_label).save(f\"{test_label_path}/label_{j}_{i}.tif\", \"tiff\")\n",
        "        else:\n",
        "            for j in range(factor):\n",
        "                augmented_image, augmented_label = augment_image(image, label, rotation=rotation)\n",
        "                Image.fromarray(augmented_image).save(f\"{train_path}/train_{j}_{i}.tif\", \"tiff\")\n",
        "                Image.fromarray(augmented_label).save(f\"{train_label_path}/label_{j}_{i}.tif\", \"tiff\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDuoLvq3WjjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augment_segmentation_dataset(50)\n",
        "augment_phc_dataset(50)\n",
        "augment_dic_dataset(50)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}